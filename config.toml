# OpticXT Configuration File
# Vision-Driven Autonomous Robot Control System

[vision]
# Camera settings
width = 640
height = 480
fps = 30
confidence_threshold = 0.5
vision_model = "yolo"  # Options: yolo, coco, custom
enable_multimodal_inference = true  # Send actual camera images to vision model

[model]
# Gemma model configuration
# Quantization method: "uqff" (faster inference, slower loading) or "isq" (fast loading, in-place quantization)
quantization_method = "isq"  # Options: "uqff", "isq"
# ISQ quantization type: Q4K (recommended), Q2K (smallest), Q5K (more accurate), Q8_0 (high quality)
isq_type = "Q4K"  # Options: Q2K, Q3K, Q4K, Q5K, Q6K, Q8_0, Q8_1
model_path = ""  # Leave empty to use default model
context_length = 4096
temperature = 0.7
top_p = 0.9
max_tokens = 512

# Remote model configuration (optional - if present, uses remote API instead of local model)
# Uncomment and configure to use a remote model instead of local inference
# [model.remote]
# base_url = "https://api.openai.com/v1"  # OpenAI API
# api_key = "your-api-key-here"
# model_name = "gpt-4o"
# temperature = 0.7  # Optional: overrides main model temperature
# top_p = 0.9        # Optional: overrides main model top_p
# max_tokens = 512   # Optional: overrides main model max_tokens
# timeout_seconds = 60
# supports_vision = true
# # Optional additional headers
# # [model.remote.additional_headers]
# # "X-Custom-Header" = "custom-value"

# Alternative examples:
# Groq (very fast inference)
# [model.remote]
# base_url = "https://api.groq.com/openai/v1"
# api_key = "your-groq-key-here"
# model_name = "llama-3.1-70b-versatile"
# supports_vision = false
# timeout_seconds = 30

# Anthropic Claude via OpenAI-compatible API
# [model.remote]
# base_url = "https://api.anthropic.com/v1"
# api_key = "your-anthropic-key-here"
# model_name = "claude-3-sonnet-20240229"
# supports_vision = true

# Local LM Studio or similar
# [model.remote]
# base_url = "http://localhost:1234/v1"
# api_key = "not-needed"
# model_name = "local-model"
# supports_vision = false
# timeout_seconds = 120

[context]
# Mandatory context system
system_prompt = "prompts/system_prompt.txt"
max_context_history = 10
include_timestamp = true

[commands]
# Available command types
enabled_commands = ["move", "rotate", "speak", "analyze", "offload"]
timeout_seconds = 30
validate_before_execution = true

[performance]
# Performance optimization
worker_threads = 4
frame_buffer_size = 10
processing_interval_ms = 100
use_gpu = true

[audio]
# Audio settings for voice input/output
enabled = true
sample_rate = 44100
channels = 1
enable_tts = true
enable_speech_recognition = false
