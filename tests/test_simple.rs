use anyhow::Result;
use opticxt::models::GemmaModel;
use opticxt::config::ModelConfig;

pub async fn test_simple_inference() -> Result<()> {
    println!("ğŸš€ Testing simple text inference...");
    
    let config = ModelConfig {
        max_tokens: 25,  // Very small for quick test
        temperature: 0.1,
        top_p: 0.8,
        context_length: 256,
    };
    
    println!("ğŸ“¥ Loading UQFF Gemma 3n model...");
    
    // Load the UQFF model
    let mut model = GemmaModel::load(None, config, "isq".to_string(), "Q4K".to_string()).await?;
    println!("âœ… Model loaded successfully!");
    
    // Single text test
    println!("\nğŸ”¤ Simple text test");
    let prompt = "Hello!";
    println!("  ğŸ“ Prompt: \"{}\"", prompt);
    
    match model.generate(prompt).await {
        Ok(result) => {
            println!("  âœ… Response: {}", result.text);
            println!("  ğŸ“Š Tokens: {}, Time: {}ms", result.tokens_generated, result.processing_time_ms);
        }
        Err(e) => {
            println!("  âŒ Generation failed: {}", e);
            return Err(e);
        }
    }
    
    println!("\nğŸ‰ Simple inference test completed successfully!");
    Ok(())
}
